{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andicleomj/Machine-Learning/blob/main/Week12/CNN/Cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WDVR3cwwfX3w"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AF6SUv6T1sN9"
      },
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Transformasi untuk normalisasi dataset CIFAR-10\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FqeYgAYn1wfn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c86c1e58-ad14-4158-cb68-baffd84d9cec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:11<00:00, 14.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Load dataset CIFAR-10\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=1000, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "venIfU5l1ygQ"
      },
      "outputs": [],
      "source": [
        "# Arsitektur CNN\n",
        "class CNN_Model(nn.Module):\n",
        "    def __init__(self, kernel_size, pool_type):\n",
        "        super(CNN_Model, self).__init__()\n",
        "\n",
        "        # Convolutional layer dengan ukuran kernel yang berbeda\n",
        "        if kernel_size == 3:\n",
        "            self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
        "            self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "            self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        elif kernel_size == 5:\n",
        "            self.conv1 = nn.Conv2d(3, 64, 5, padding=2)\n",
        "            self.conv2 = nn.Conv2d(64, 128, 5, padding=2)\n",
        "            self.conv3 = nn.Conv2d(128, 256, 5, padding=2)\n",
        "        elif kernel_size == 7:\n",
        "            self.conv1 = nn.Conv2d(3, 64, 7, padding=3)\n",
        "            self.conv2 = nn.Conv2d(64, 128, 7, padding=3)\n",
        "            self.conv3 = nn.Conv2d(128, 256, 7, padding=3)\n",
        "\n",
        "        # MaxPooling atau Average Pooling\n",
        "        if pool_type == 'max':\n",
        "            self.pool = nn.MaxPool2d(2, 2)\n",
        "        elif pool_type == 'avg':\n",
        "            self.pool = nn.AvgPool2d(2, 2)\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc1 = nn.Linear(256 * 4 * 4, 1024)  # setelah tiga pooling 2x2\n",
        "        self.fc2 = nn.Linear(1024, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = self.pool(torch.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 256 * 4 * 4)  # Flatten tensor\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "01M3kd1T1_vq"
      },
      "outputs": [],
      "source": [
        "# Fungsi untuk melatih dan menguji model\n",
        "def train_and_evaluate(model, optimizer, criterion, epochs, lr_scheduler=None, early_stopper=None):\n",
        "    model.to(device)\n",
        "    train_losses = []\n",
        "    test_accuracy = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        # Training loop\n",
        "        for inputs, labels in trainloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_losses.append(running_loss / len(trainloader))\n",
        "\n",
        "        # Menghitung akurasi pada set pengujian\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in testloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        test_accuracy.append(accuracy)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(trainloader)}, Test Accuracy: {accuracy}%\")\n",
        "\n",
        "        if lr_scheduler:\n",
        "            lr_scheduler.step()\n",
        "\n",
        "        if early_stopper and early_stopper(epoch, accuracy):\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    return train_losses, test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4TOSDHCx2Blx"
      },
      "outputs": [],
      "source": [
        "# Setup Optimizer dan Scheduler\n",
        "def get_optimizer_and_scheduler(optimizer_name, model, lr=0.001):\n",
        "    if optimizer_name == 'sgd':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    elif optimizer_name == 'rmsprop':\n",
        "        optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
        "    elif optimizer_name == 'adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    scheduler = StepLR(optimizer, step_size=50, gamma=0.1)  # Learning rate scheduler\n",
        "\n",
        "    return optimizer, scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "S4B30SrPDpZR"
      },
      "outputs": [],
      "source": [
        "# Callback Early Stopping\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, delta=0):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.best_acc = None\n",
        "        self.counter = 0\n",
        "\n",
        "    def __call__(self, epoch, accuracy):\n",
        "        if self.best_acc is None:\n",
        "            self.best_acc = accuracy\n",
        "        elif accuracy - self.best_acc < self.delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        else:\n",
        "            self.best_acc = accuracy\n",
        "            self.counter = 0\n",
        "\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xM9jnQYgD2pu",
        "outputId": "900d3c53-d188-43e3-bcd8-764eb1532b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training dengan kernel_size=3, pool_type=max, optimizer=sgd, epochs=5\n",
            "Epoch 1/5, Loss: 2.1586260650773794, Test Accuracy: 32.19%\n",
            "Epoch 2/5, Loss: 1.749044663460968, Test Accuracy: 41.98%\n",
            "Epoch 3/5, Loss: 1.5282290161723067, Test Accuracy: 47.85%\n",
            "Epoch 4/5, Loss: 1.4012161522265285, Test Accuracy: 51.96%\n",
            "Epoch 5/5, Loss: 1.3170155464383342, Test Accuracy: 53.42%\n",
            "Training time: 2221.46337556839 detik\n",
            "Akurasi terbaik pada epoch terakhir: 53.42%\n",
            "\n",
            "Training dengan kernel_size=3, pool_type=max, optimizer=sgd, epochs=50\n",
            "Epoch 1/50, Loss: 2.1750830965273824, Test Accuracy: 31.34%\n",
            "Epoch 2/50, Loss: 1.7724833133275553, Test Accuracy: 41.26%\n",
            "Epoch 3/50, Loss: 1.5420128846412424, Test Accuracy: 47.3%\n",
            "Epoch 4/50, Loss: 1.4235040510402006, Test Accuracy: 51.19%\n",
            "Epoch 5/50, Loss: 1.335592928749826, Test Accuracy: 53.52%\n",
            "Epoch 6/50, Loss: 1.2596959106605072, Test Accuracy: 56.11%\n",
            "Epoch 7/50, Loss: 1.187791127911614, Test Accuracy: 58.55%\n",
            "Epoch 8/50, Loss: 1.1172704247714917, Test Accuracy: 60.65%\n",
            "Epoch 9/50, Loss: 1.0530535072621787, Test Accuracy: 63.35%\n",
            "Epoch 10/50, Loss: 0.9902292341374985, Test Accuracy: 64.48%\n",
            "Epoch 11/50, Loss: 0.9362156217360436, Test Accuracy: 67.2%\n",
            "Epoch 12/50, Loss: 0.8829147091606999, Test Accuracy: 67.41%\n",
            "Epoch 13/50, Loss: 0.8360465486031359, Test Accuracy: 68.98%\n",
            "Epoch 14/50, Loss: 0.7906907692056178, Test Accuracy: 68.59%\n",
            "Epoch 15/50, Loss: 0.7507417230197536, Test Accuracy: 70.83%\n",
            "Epoch 16/50, Loss: 0.7151548101773957, Test Accuracy: 71.35%\n",
            "Epoch 17/50, Loss: 0.6711990189979143, Test Accuracy: 71.82%\n",
            "Epoch 18/50, Loss: 0.6358775275061502, Test Accuracy: 72.68%\n",
            "Epoch 19/50, Loss: 0.5944585660877435, Test Accuracy: 73.86%\n",
            "Epoch 20/50, Loss: 0.5587102638943421, Test Accuracy: 73.18%\n",
            "Epoch 21/50, Loss: 0.5218492696047439, Test Accuracy: 73.9%\n",
            "Epoch 22/50, Loss: 0.4838110295212482, Test Accuracy: 74.0%\n",
            "Epoch 23/50, Loss: 0.4499920981047708, Test Accuracy: 75.16%\n",
            "Epoch 24/50, Loss: 0.41220878388570703, Test Accuracy: 75.26%\n",
            "Epoch 25/50, Loss: 0.3711478334406148, Test Accuracy: 74.85%\n",
            "Epoch 26/50, Loss: 0.33581219382984256, Test Accuracy: 75.75%\n",
            "Epoch 27/50, Loss: 0.3005059765237372, Test Accuracy: 75.84%\n",
            "Epoch 28/50, Loss: 0.2617675288177817, Test Accuracy: 75.24%\n",
            "Epoch 29/50, Loss: 0.23229236711207255, Test Accuracy: 74.62%\n",
            "Epoch 30/50, Loss: 0.19863651073573496, Test Accuracy: 76.06%\n",
            "Epoch 31/50, Loss: 0.16995382232262807, Test Accuracy: 75.66%\n",
            "Epoch 32/50, Loss: 0.14341283261375812, Test Accuracy: 75.83%\n",
            "Epoch 33/50, Loss: 0.11266971140375832, Test Accuracy: 75.49%\n",
            "Epoch 34/50, Loss: 0.09324811101960176, Test Accuracy: 76.33%\n",
            "Epoch 35/50, Loss: 0.07406720426052694, Test Accuracy: 75.47%\n",
            "Epoch 36/50, Loss: 0.055872541436653995, Test Accuracy: 76.23%\n",
            "Epoch 37/50, Loss: 0.03869013054429761, Test Accuracy: 76.43%\n",
            "Epoch 38/50, Loss: 0.029361634922530647, Test Accuracy: 76.55%\n",
            "Epoch 39/50, Loss: 0.019752226931893307, Test Accuracy: 76.71%\n",
            "Epoch 40/50, Loss: 0.01593506539656121, Test Accuracy: 76.71%\n",
            "Epoch 41/50, Loss: 0.010213008583666246, Test Accuracy: 77.15%\n",
            "Epoch 42/50, Loss: 0.007910319259795158, Test Accuracy: 77.03%\n",
            "Epoch 43/50, Loss: 0.006635952982372698, Test Accuracy: 76.88%\n",
            "Epoch 44/50, Loss: 0.0055909183813030346, Test Accuracy: 77.11%\n",
            "Epoch 45/50, Loss: 0.0048997253090228956, Test Accuracy: 77.1%\n",
            "Epoch 46/50, Loss: 0.004148256365040703, Test Accuracy: 76.92%\n",
            "Epoch 47/50, Loss: 0.0038211818488524357, Test Accuracy: 77.06%\n",
            "Epoch 48/50, Loss: 0.003413840778805601, Test Accuracy: 76.97%\n",
            "Epoch 49/50, Loss: 0.0031267302811962775, Test Accuracy: 76.99%\n",
            "Epoch 50/50, Loss: 0.0028841887230632345, Test Accuracy: 76.98%\n",
            "Training time: 18481.628251791 detik\n",
            "Akurasi terbaik pada epoch terakhir: 76.98%\n",
            "\n",
            "Training dengan kernel_size=3, pool_type=max, optimizer=sgd, epochs=100\n",
            "Epoch 1/100, Loss: 2.159378122795573, Test Accuracy: 31.12%\n",
            "Epoch 2/100, Loss: 1.7688820703560129, Test Accuracy: 40.92%\n",
            "Epoch 3/100, Loss: 1.530103783930659, Test Accuracy: 48.63%\n"
          ]
        }
      ],
      "source": [
        "# Melatih dan menguji model dengan pengaturan yang berbeda\n",
        "kernel_sizes = [3, 5, 7]\n",
        "pool_types = ['max', 'avg']\n",
        "optimizers = ['sgd', 'rmsprop', 'adam']\n",
        "epochs_list = [5, 50, 100, 250, 350]\n",
        "\n",
        "for kernel_size in kernel_sizes:\n",
        "    for pool_type in pool_types:\n",
        "        for optimizer_name in optimizers:\n",
        "            for epochs in epochs_list:\n",
        "                print(f\"\\nTraining dengan kernel_size={kernel_size}, pool_type={pool_type}, optimizer={optimizer_name}, epochs={epochs}\")\n",
        "\n",
        "                # Inisialisasi model, optimizer, dan scheduler\n",
        "                model = CNN_Model(kernel_size=kernel_size, pool_type=pool_type)\n",
        "                optimizer, scheduler = get_optimizer_and_scheduler(optimizer_name, model)\n",
        "                criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "                # Early Stopping\n",
        "                early_stopper = EarlyStopping(patience=10, delta=0.1)\n",
        "\n",
        "                # Latih dan evaluasi model\n",
        "                start_time = time.time()\n",
        "                train_losses, test_accuracy = train_and_evaluate(model, optimizer, criterion, epochs, lr_scheduler=scheduler, early_stopper=early_stopper)\n",
        "                end_time = time.time()\n",
        "\n",
        "                print(f\"Training time: {end_time - start_time} detik\")\n",
        "                print(f\"Akurasi terbaik pada epoch terakhir: {test_accuracy[-1]}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47snbPGP3Qvu"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlMugMPuQozFRtpih9c9rj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}